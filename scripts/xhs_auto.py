#!/usr/bin/env python3
"""
å°çº¢ä¹¦è‡ªåŠ¨åŒ–å‘å¸ƒå·¥å…·
åŸºäº Playwright æµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼Œæ”¯æŒæ‰«ç ç™»å½•ã€æŒä¹…åŒ–ä¼šè¯ã€è‡ªåŠ¨å‘å¸–
"""

import os
import sys
import json
import time
import logging
import argparse
from datetime import datetime
from pathlib import Path

# é…ç½®æ—¥å¿—
LOG_DIR = Path(__file__).parent.parent / 'logs'
LOG_DIR.mkdir(exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(
            LOG_DIR / f'xhs_{datetime.now():%Y%m%d}.log',
            encoding='utf-8'
        )
    ]
)
log = logging.getLogger(__name__)

# è·¯å¾„å¸¸é‡
SKILL_DIR = Path(__file__).parent.parent
BROWSER_DATA = SKILL_DIR / 'browser_data'
CONTENT_DIR = SKILL_DIR / 'content'
SCREENSHOTS_DIR = SKILL_DIR / 'screenshots'

for d in [BROWSER_DATA, CONTENT_DIR, SCREENSHOTS_DIR]:
    d.mkdir(exist_ok=True)

# å°çº¢ä¹¦ URL
XHS_HOME = 'https://www.xiaohongshu.com'
XHS_CREATOR = 'https://creator.xiaohongshu.com'
XHS_PUBLISH = 'https://creator.xiaohongshu.com/publish/publish'
XHS_LOGIN = 'https://creator.xiaohongshu.com/login'


def create_browser_context(playwright, headless=False):
    """åˆ›å»ºæŒä¹…åŒ–æµè§ˆå™¨ä¸Šä¸‹æ–‡ï¼ˆå«åæ£€æµ‹ï¼‰"""
    sys.path.insert(0, str(Path(__file__).parent))
    from stealth import random_user_agent, random_viewport, get_stealth_args, get_stealth_ignore_args, apply_stealth

    ua = random_user_agent()
    vp = random_viewport()
    log.info(f'æµè§ˆå™¨æŒ‡çº¹: UA={ua[:50]}... viewport={vp["width"]}x{vp["height"]}')

    context = playwright.chromium.launch_persistent_context(
        user_data_dir=str(BROWSER_DATA),
        headless=headless,
        viewport=vp,
        user_agent=ua,
        locale='zh-CN',
        timezone_id='Asia/Shanghai',
        args=get_stealth_args(),
        ignore_default_args=get_stealth_ignore_args(),
    )
    apply_stealth(context)
    return context


def check_login(page, timeout=5000):
    """æ£€æŸ¥æ˜¯å¦å·²ç™»å½•"""
    try:
        page.goto(XHS_CREATOR, wait_until='domcontentloaded', timeout=15000)
        time.sleep(2)

        # å¦‚æœè·³è½¬åˆ°äº†ç™»å½•é¡µï¼Œè¯´æ˜æœªç™»å½•
        if '/login' in page.url:
            return False

        # å°è¯•æ£€æµ‹é¡µé¢ä¸Šçš„ç”¨æˆ·ä¿¡æ¯å…ƒç´ 
        try:
            page.wait_for_selector('.user, .creator-header, .sidebar', timeout=timeout)
            return True
        except Exception:
            # æ²¡è·³è½¬åˆ°ç™»å½•é¡µï¼Œä¹Ÿå¯èƒ½å·²ç™»å½•
            return '/login' not in page.url

    except Exception as e:
        log.warning(f'æ£€æŸ¥ç™»å½•çŠ¶æ€æ—¶å‡ºé”™: {e}')
        return False


def do_login(page, timeout=300):
    """
    æ‰§è¡Œæ‰«ç ç™»å½•
    è¿”å›æˆªå›¾è·¯å¾„ï¼ˆäºŒç»´ç æˆªå›¾ï¼‰ï¼Œç”¨æˆ·éœ€è¦ç”¨å°çº¢ä¹¦ APP æ‰«ç 
    """
    log.info('å¼€å§‹ç™»å½•æµç¨‹...')
    page.goto(XHS_LOGIN, wait_until='domcontentloaded', timeout=15000)
    time.sleep(5)

    # ç‚¹å‡»å·¦ä¸Šè§’äºŒç»´ç å°å›¾æ ‡ï¼Œåˆ‡æ¢åˆ°æ‰«ç ç™»å½•æ¨¡å¼
    # å°çº¢ä¹¦åˆ›ä½œè€…å¹³å°é»˜è®¤æ˜¾ç¤ºçŸ­ä¿¡ç™»å½•ï¼Œéœ€è¦ç‚¹å‡»äºŒç»´ç å›¾æ ‡åˆ‡æ¢
    try:
        qr_icon = page.locator('img.css-wemwzq').first
        if qr_icon.is_visible():
            qr_icon.click()
            log.info('å·²ç‚¹å‡»äºŒç»´ç å›¾æ ‡ï¼Œåˆ‡æ¢åˆ°æ‰«ç ç™»å½•æ¨¡å¼')
            time.sleep(3)
        else:
            log.warning('æœªæ‰¾åˆ°äºŒç»´ç å›¾æ ‡ï¼Œå°è¯•å¤‡ç”¨æ–¹å¼')
            # å¤‡ç”¨ï¼šå°è¯•ç‚¹å‡»ä»»ä½•å°çš„äºŒç»´ç å›¾ç‰‡
            small_imgs = page.locator('.login-box-container img')
            for i in range(small_imgs.count()):
                img = small_imgs.nth(i)
                box = img.bounding_box()
                if box and box['width'] < 100 and box['height'] < 100:
                    img.click()
                    log.info('å·²ç‚¹å‡»å¤‡ç”¨äºŒç»´ç å›¾æ ‡')
                    time.sleep(3)
                    break
    except Exception as e:
        log.warning(f'åˆ‡æ¢æ‰«ç æ¨¡å¼å¤±è´¥: {e}')

    # æˆªå–æ‰«ç ç™»å½•é¡µé¢çš„äºŒç»´ç åŒºåŸŸ
    qr_screenshot = SCREENSHOTS_DIR / f'qrcode_{datetime.now():%Y%m%d_%H%M%S}.png'
    # å°è¯•åªæˆªå–äºŒç»´ç å›¾ç‰‡åŒºåŸŸ
    try:
        qr_img = page.locator('img.css-1lhmg90').first
        if qr_img.is_visible():
            qr_img.screenshot(path=str(qr_screenshot))
            log.info(f'äºŒç»´ç æˆªå›¾å·²ä¿å­˜ï¼ˆå…ƒç´ æˆªå›¾ï¼‰: {qr_screenshot}')
        else:
            page.screenshot(path=str(qr_screenshot), full_page=False)
            log.info(f'äºŒç»´ç æˆªå›¾å·²ä¿å­˜ï¼ˆå…¨é¡µæˆªå›¾ï¼‰: {qr_screenshot}')
    except Exception:
        page.screenshot(path=str(qr_screenshot), full_page=False)
        log.info(f'äºŒç»´ç æˆªå›¾å·²ä¿å­˜ï¼ˆå…¨é¡µæˆªå›¾ï¼‰: {qr_screenshot}')

    # ç­‰å¾…ç™»å½•æˆåŠŸ
    log.info(f'è¯·ç”¨å°çº¢ä¹¦ APP æ‰«æäºŒç»´ç ç™»å½•ï¼ˆ{timeout}ç§’è¶…æ—¶ï¼‰...')
    start = time.time()
    while time.time() - start < timeout:
        time.sleep(3)
        current_url = page.url
        if '/login' not in current_url:
            log.info('ç™»å½•æˆåŠŸï¼')
            success_shot = SCREENSHOTS_DIR / f'login_success_{datetime.now():%Y%m%d_%H%M%S}.png'
            page.screenshot(path=str(success_shot))
            return str(qr_screenshot)

    raise TimeoutError(f'ç™»å½•è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰ï¼Œè¯·é‡è¯•')


def publish_note(page, title, content, tags=None, images=None, dry_run=False, auto_image=True, image_count=1):
    """
    å‘å¸ƒå°çº¢ä¹¦ç¬”è®°ï¼ˆå«é”™è¯¯æ¢å¤ï¼‰

    Args:
        page: Playwright page å¯¹è±¡
        title: ç¬”è®°æ ‡é¢˜ï¼ˆä¸è¶…è¿‡20å­—ï¼‰
        content: ç¬”è®°æ­£æ–‡ï¼ˆä¸è¶…è¿‡1000å­—ï¼‰
        tags: æ ‡ç­¾åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        images: å›¾ç‰‡è·¯å¾„åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œä¸ä¼ åˆ™è‡ªåŠ¨ç”Ÿæˆé…å›¾ï¼‰
        dry_run: è¯•è¿è¡Œï¼Œä¸å®é™…ç‚¹å‡»å‘å¸ƒ
        auto_image: æ²¡æœ‰å›¾ç‰‡æ—¶æ˜¯å¦è‡ªåŠ¨ç”¨ AI ç”Ÿæˆé…å›¾ï¼ˆé»˜è®¤ Trueï¼‰
        image_count: è‡ªåŠ¨ç”Ÿæˆå›¾ç‰‡æ•°é‡ï¼ˆ1-9ï¼Œé»˜è®¤ 1ï¼Œä»…åœ¨ auto_image ä¸”æ—  images æ—¶ç”Ÿæ•ˆï¼‰
    """
    sys.path.insert(0, str(Path(__file__).parent))
    from recovery import safe_navigate, save_error_snapshot, check_page_health, recover_page

    log.info(f'å¼€å§‹å‘å¸ƒç¬”è®°: {title}')

    # 1. å¯¼èˆªåˆ°å‘å¸ƒé¡µï¼ˆå¸¦é‡è¯•ï¼‰
    try:
        safe_navigate(page, XHS_PUBLISH, timeout=20000, retries=3)
    except Exception as e:
        log.error(f'å¯¼èˆªåˆ°å‘å¸ƒé¡µå¤±è´¥: {e}')
        shot = save_error_snapshot(page, 'nav_publish_fail')
        _save_report(title, content, tags, False, f'å¯¼èˆªå¤±è´¥: {e}')
        return {'success': False, 'error': f'å¯¼èˆªåˆ°å‘å¸ƒé¡µå¤±è´¥: {e}', 'screenshot': shot}
    time.sleep(5)

    # 2. ç”¨ JS ç‚¹å‡»ã€Œä¸Šä¼ å›¾æ–‡ã€TABï¼ˆé¿å…è§†å£å¤–ç‚¹å‡»å¤±è´¥ï¼‰
    try:
        result = page.evaluate('''() => {
            const all = document.querySelectorAll('*');
            for (const el of all) {
                if (el.children.length === 0 && el.textContent.trim() === 'ä¸Šä¼ å›¾æ–‡') {
                    el.click();
                    return true;
                }
            }
            return false;
        }''')
        if result:
            log.info('å·²ç‚¹å‡»ä¸Šä¼ å›¾æ–‡ TAB')
        else:
            log.info('æœªæ‰¾åˆ°ä¸Šä¼ å›¾æ–‡ TABï¼Œå¯èƒ½å·²åœ¨å›¾æ–‡æ¨¡å¼')
        time.sleep(3)
    except Exception as e:
        log.warning(f'ç‚¹å‡»ä¸Šä¼ å›¾æ–‡ TAB å¤±è´¥: {e}')

    # 3. ä¸Šä¼ å›¾ç‰‡ï¼ˆæ— å›¾ç‰‡æ—¶è‡ªåŠ¨ AI ç”Ÿæˆé…å›¾ï¼‰
    image_paths = images or []
    if not image_paths and auto_image:
        if image_count > 1:
            log.info(f'æœªæä¾›å›¾ç‰‡ï¼Œè‡ªåŠ¨ç”Ÿæˆ {image_count} å¼  AI é…å›¾...')
            generated = _auto_generate_multi_images(title, content, count=image_count)
            if generated:
                image_paths = generated
                log.info(f'å¤šå›¾ç”Ÿæˆå®Œæˆ: {len(generated)} å¼ ')
            else:
                log.warning('å¤šå›¾ç”Ÿæˆå…¨éƒ¨å¤±è´¥ï¼Œå°è¯•å•å¼ ...')
                single = _auto_generate_image(title, content)
                if single:
                    image_paths = [single]
        else:
            log.info('æœªæä¾›å›¾ç‰‡ï¼Œè‡ªåŠ¨ç”Ÿæˆ AI é…å›¾...')
            generated = _auto_generate_image(title, content)
            if generated:
                image_paths = [generated]
                log.info(f'AI é…å›¾ç”ŸæˆæˆåŠŸ: {generated}')
            else:
                log.warning('AI é…å›¾ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å°é¢')

        if not image_paths:
            default_cover = CONTENT_DIR / 'default_cover.png'
            if not default_cover.exists():
                _generate_default_cover(default_cover, title)
            image_paths = [str(default_cover)]
    elif not image_paths:
        default_cover = CONTENT_DIR / 'default_cover.png'
        if not default_cover.exists():
            _generate_default_cover(default_cover, title)
        image_paths = [str(default_cover)]

    try:
        upload_input = page.locator('input[type="file"]').first
        upload_input.set_input_files(image_paths)
        log.info(f'å·²ä¸Šä¼  {len(image_paths)} å¼ å›¾ç‰‡')
        # å¤šå›¾ä¸Šä¼ éœ€è¦æ›´é•¿ç­‰å¾…æ—¶é—´
        wait_sec = max(8, len(image_paths) * 4)
        time.sleep(wait_sec)
    except Exception as e:
        log.warning(f'å›¾ç‰‡ä¸Šä¼ å¤±è´¥: {e}')

    # 4. å¡«å†™æ ‡é¢˜
    try:
        title_input = page.locator('input[placeholder*="æ ‡é¢˜"]').first
        title_input.click()
        title_input.fill(title[:20])
        log.info(f'æ ‡é¢˜å·²å¡«å†™: {title[:20]}')
        time.sleep(0.5)
    except Exception as e:
        log.error(f'æ ‡é¢˜å¡«å†™å¤±è´¥: {e}')

    # 5. å¡«å†™æ­£æ–‡ï¼ˆtiptap ProseMirror ç¼–è¾‘å™¨ï¼‰
    try:
        body_editor = page.locator('div.ProseMirror[contenteditable="true"]').first
        if not body_editor.is_visible():
            body_editor = page.locator('[contenteditable="true"]').first
        body_editor.click()
        body_editor.type(content[:1000], delay=20)
        log.info(f'æ­£æ–‡å·²å¡«å†™ï¼ˆ{len(content[:1000])}å­—ï¼‰')
        time.sleep(0.5)
    except Exception as e:
        log.error(f'æ­£æ–‡å¡«å†™å¤±è´¥: {e}')

    # 6. æ·»åŠ æ ‡ç­¾ï¼ˆé€šè¿‡è¯é¢˜æŒ‰é’®ï¼‰
    if tags:
        _add_tags(page, tags)

    # æˆªå›¾è®°å½•
    pre_publish_shot = SCREENSHOTS_DIR / f'pre_publish_{datetime.now():%Y%m%d_%H%M%S}.png'
    page.screenshot(path=str(pre_publish_shot), full_page=True)
    log.info(f'å‘å¸ƒå‰æˆªå›¾: {pre_publish_shot}')

    # 7. ç‚¹å‡»å‘å¸ƒ
    if dry_run:
        log.info('[DRY RUN] è¯•è¿è¡Œæ¨¡å¼ï¼Œè·³è¿‡å‘å¸ƒ')
        return {
            'success': True,
            'dry_run': True,
            'title': title,
            'screenshot': str(pre_publish_shot)
        }

    # å‘å¸ƒï¼ˆå¸¦é‡è¯•ï¼‰
    max_publish_retries = 3
    for attempt in range(1, max_publish_retries + 1):
        try:
            # æ£€æŸ¥é¡µé¢å¥åº·
            health = check_page_health(page)
            if not health['ok']:
                log.warning(f'å‘å¸ƒå‰é¡µé¢å¼‚å¸¸: {health.get("error")}ï¼Œå°è¯•æ¢å¤...')
                if not recover_page(page, XHS_PUBLISH):
                    raise RuntimeError('é¡µé¢æ¢å¤å¤±è´¥')

            publish_btn = page.locator('button:has-text("å‘å¸ƒ")').last
            publish_btn.wait_for(state='visible', timeout=5000)
            publish_btn.click()
            log.info('å·²ç‚¹å‡»å‘å¸ƒæŒ‰é’®')
            time.sleep(8)

            # å‘å¸ƒåæˆªå›¾
            post_shot = SCREENSHOTS_DIR / f'published_{datetime.now():%Y%m%d_%H%M%S}.png'
            page.screenshot(path=str(post_shot))
            log.info(f'å‘å¸ƒå®Œæˆï¼æˆªå›¾: {post_shot}')

            # ä¿å­˜å‘å¸ƒè®°å½•
            _save_report(title, content, tags, True)

            return {
                'success': True,
                'title': title,
                'screenshot': str(post_shot)
            }

        except Exception as e:
            log.warning(f'å‘å¸ƒå°è¯• {attempt}/{max_publish_retries} å¤±è´¥: {e}')
            save_error_snapshot(page, f'publish_retry{attempt}')
            if attempt < max_publish_retries:
                time.sleep(5)
            else:
                log.error(f'å‘å¸ƒåœ¨ {max_publish_retries} æ¬¡å°è¯•åä»å¤±è´¥: {e}')
                err_shot = save_error_snapshot(page, 'publish_final_fail')
                _save_report(title, content, tags, False, str(e))
                return {
                    'success': False,
                    'error': str(e),
                    'screenshot': err_shot,
                    'retries': max_publish_retries,
                }


def _add_tags(page, tags):
    """æ·»åŠ æ ‡ç­¾ - é€šè¿‡è¯é¢˜æŒ‰é’®æˆ–åœ¨æ­£æ–‡ä¸­è¾“å…¥ #"""
    added = 0
    for tag in tags[:10]:  # æœ€å¤š10ä¸ªæ ‡ç­¾
        try:
            # åœ¨æ­£æ–‡ç¼–è¾‘å™¨ä¸­è¾“å…¥ # è§¦å‘æ ‡ç­¾è”æƒ³
            editor = page.locator('div.ProseMirror[contenteditable="true"]').first
            if not editor.is_visible():
                editor = page.locator('[contenteditable="true"]').first
            editor.click()
            editor.type(f' #{tag}', delay=80)
            time.sleep(1.5)

            # å°è¯•ä»è”æƒ³åˆ—è¡¨ä¸­é€‰æ‹©ç¬¬ä¸€ä¸ªåŒ¹é…é¡¹
            try:
                suggestion = page.locator(f'[class*="topic"] >> text="{tag}"').first
                if suggestion.is_visible(timeout=2000):
                    suggestion.click()
                    added += 1
                    time.sleep(0.5)
                    continue
            except Exception:
                pass

            # å¤‡ç”¨ï¼šå°è¯•ç‚¹å‡»ä»»ä½•å¼¹å‡ºçš„è”æƒ³åˆ—è¡¨é¡¹
            try:
                popup_item = page.locator('[class*="suggest"] li, [class*="topic-list"] div, [class*="hash-tag"] div').first
                if popup_item.is_visible(timeout=1000):
                    popup_item.click()
                    added += 1
                    time.sleep(0.5)
                    continue
            except Exception:
                pass

            # è”æƒ³æ²¡åŒ¹é…åˆ°ï¼Œæ ‡ç­¾æ–‡æœ¬å·²è¾“å…¥
            added += 1

        except Exception as e:
            log.warning(f'æ·»åŠ æ ‡ç­¾ "{tag}" å¤±è´¥: {e}')

    log.info(f'å·²æ·»åŠ  {added} ä¸ªæ ‡ç­¾')


def _auto_generate_image(title, content):
    """
    æ ¹æ®ç¬”è®°æ ‡é¢˜å’Œæ­£æ–‡è‡ªåŠ¨ç”Ÿæˆ AI é…å›¾
    ä¼˜å…ˆ nano-banana-proï¼Œé™çº§ qwen-image
    è¿”å›å›¾ç‰‡è·¯å¾„æˆ– None
    """
    try:
        # å¯¼å…¥åŒç›®å½•ä¸‹çš„ image_gen æ¨¡å—
        sys.path.insert(0, str(Path(__file__).parent))
        from image_gen import generate_image

        # ç”¨æ ‡é¢˜+æ­£æ–‡å‰100å­—æ„é€ å›¾ç‰‡ prompt
        context = content[:100] if content else ''
        prompt = (
            f"ä¸ºå°çº¢ä¹¦ç¬”è®°ç”Ÿæˆä¸€å¼ ç²¾ç¾é…å›¾ã€‚"
            f"ç¬”è®°æ ‡é¢˜ï¼š{title}ã€‚"
            f"å†…å®¹æ‘˜è¦ï¼š{context}ã€‚"
            f"è¦æ±‚ï¼šé«˜è´¨é‡ã€å¸å¼•çœ¼çƒã€é€‚åˆç¤¾äº¤åª’ä½“ã€è‰²å½©é²œæ˜ã€3:4ç«–ç‰ˆæ„å›¾"
        )

        ts = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_path = str(CONTENT_DIR / f'ai_cover_{ts}.png')

        result = generate_image(prompt, output_path, resolution='1K')
        if result['success']:
            log.info(f'AI é…å›¾ç”ŸæˆæˆåŠŸ [å¼•æ“: {result["engine"]}]: {output_path}')
            return output_path
        else:
            log.warning(f'AI é…å›¾ç”Ÿæˆå¤±è´¥: {result.get("error", "æœªçŸ¥")}')
            return None

    except Exception as e:
        log.warning(f'AI é…å›¾ç”Ÿæˆå¼‚å¸¸: {e}')
        return None


def _split_content_sections(content):
    """å°†æ­£æ–‡æŒ‰æ®µè½/å°æ ‡é¢˜æ‹†åˆ†æˆè‹¥å¹²æ®µï¼Œç”¨äºç”Ÿæˆåˆ†æ®µé…å›¾"""
    import re
    sections = []
    current = []
    for line in content.split('\n'):
        stripped = line.strip()
        # é‡åˆ°å°æ ‡é¢˜æ—¶åˆ‡æ®µ
        if re.match(r'^[ã€\[#âœ…âŒğŸ”¥ğŸ’¡ğŸ“ŒğŸ¯ğŸ·ï¸ğŸ“]', stripped) and current:
            text = '\n'.join(current).strip()
            if len(text) > 15:
                sections.append(text)
            current = []
        if stripped:
            current.append(stripped)
    if current:
        text = '\n'.join(current).strip()
        if len(text) > 15:
            sections.append(text)
    return sections if sections else [content]


def _auto_generate_multi_images(title, content, count=3):
    """
    æ ¹æ®ç¬”è®°æ ‡é¢˜å’Œæ­£æ–‡è‡ªåŠ¨ç”Ÿæˆå¤šå¼  AI é…å›¾ã€‚
    ç¬¬ 1 å¼ ä¸ºå°é¢ï¼ˆ3:4 ç«–ç‰ˆï¼‰ï¼Œåç»­ä¸ºå†…å®¹å›¾ï¼ˆ3:4 ç«–ç‰ˆï¼‰ã€‚
    æ¯å¼ å›¾çš„ prompt åŸºäºå¯¹åº”çš„å†…å®¹æ®µè½ï¼Œç¡®ä¿å›¾æ–‡åŒ¹é…ã€‚

    Args:
        title: ç¬”è®°æ ‡é¢˜
        content: ç¬”è®°æ­£æ–‡
        count: ç”Ÿæˆå›¾ç‰‡æ•°é‡ï¼ˆ1-9ï¼Œé»˜è®¤ 3ï¼‰

    Returns:
        list[str]: ç”ŸæˆæˆåŠŸçš„å›¾ç‰‡è·¯å¾„åˆ—è¡¨ï¼ˆå¯èƒ½å°‘äº countï¼‰
    """
    count = max(1, min(9, count))
    sys.path.insert(0, str(Path(__file__).parent))
    from image_gen import generate_image

    # æ‹†åˆ†å†…å®¹æ®µè½
    sections = _split_content_sections(content)

    # æ„å»ºæ¯å¼ å›¾çš„ prompt
    prompts = []

    # å°é¢ï¼šçªå‡ºæ ‡é¢˜ï¼Œå¸å¼•çœ¼çƒ
    prompts.append(
        f"ä¸ºå°çº¢ä¹¦ç¬”è®°ç”Ÿæˆä¸€å¼ ç²¾ç¾å°é¢å›¾ã€‚"
        f"æ ‡é¢˜ï¼š{title}ã€‚"
        f"è¦æ±‚ï¼šé«˜è´¨é‡ã€å¸å¼•çœ¼çƒã€è‰²å½©é²œæ˜ã€3:4ç«–ç‰ˆæ„å›¾ã€é€‚åˆç¤¾äº¤åª’ä½“å°é¢ã€"
        f"ç”»é¢å¹²å‡€æœ‰è®¾è®¡æ„Ÿã€ä¸è¦åŒ…å«æ–‡å­—"
    )

    # å†…å®¹å›¾ï¼šæ¯å¼ å¯¹åº”ä¸€ä¸ªæ®µè½
    for i in range(1, count):
        if i - 1 < len(sections):
            section = sections[i - 1][:150]
        else:
            # æ®µè½ä¸å¤Ÿæ—¶ï¼Œç”¨æ ‡é¢˜+åºå·ç”Ÿæˆå˜ä½“
            section = f"{title} ç¬¬{i}éƒ¨åˆ†"
        prompts.append(
            f"ä¸ºå°çº¢ä¹¦ç¬”è®°ç”Ÿæˆä¸€å¼ å†…å®¹é…å›¾ï¼ˆç¬¬{i+1}å¼ ï¼‰ã€‚"
            f"ç¬”è®°æ ‡é¢˜ï¼š{title}ã€‚"
            f"æœ¬é¡µå†…å®¹ï¼š{section}ã€‚"
            f"è¦æ±‚ï¼šé«˜è´¨é‡ã€3:4ç«–ç‰ˆæ„å›¾ã€ä¸å†…å®¹ç›¸å…³ã€é£æ ¼ç»Ÿä¸€ã€ä¸è¦åŒ…å«æ–‡å­—"
        )

    # é€å¼ ç”Ÿæˆ
    generated = []
    ts = datetime.now().strftime('%Y%m%d_%H%M%S')
    for idx, prompt in enumerate(prompts):
        suffix = 'cover' if idx == 0 else f'page{idx}'
        output_path = str(CONTENT_DIR / f'ai_{suffix}_{ts}.png')
        log.info(f'ç”Ÿæˆç¬¬ {idx+1}/{count} å¼ å›¾ç‰‡...')
        try:
            result = generate_image(prompt, output_path, resolution='1K')
            if result['success']:
                generated.append(output_path)
                log.info(f'  âœ“ ç¬¬ {idx+1} å¼ æˆåŠŸ [{result["engine"]}]: {output_path}')
            else:
                log.warning(f'  âœ— ç¬¬ {idx+1} å¼ å¤±è´¥: {result.get("error", "æœªçŸ¥")}')
        except Exception as e:
            log.warning(f'  âœ— ç¬¬ {idx+1} å¼ å¼‚å¸¸: {e}')
        # è¯·æ±‚é—´éš”ï¼Œé¿å…è§¦å‘ API é€Ÿç‡é™åˆ¶
        if idx < len(prompts) - 1:
            time.sleep(5)

    log.info(f'å¤šå›¾ç”Ÿæˆå®Œæˆ: {len(generated)}/{count} å¼ æˆåŠŸ')
    return generated


def _generate_default_cover(path, title=''):
    """ç”Ÿæˆé»˜è®¤å°é¢å›¾"""
    try:
        from PIL import Image, ImageDraw, ImageFont

        img = Image.new('RGB', (1080, 1440), color=(255, 240, 245))
        draw = ImageDraw.Draw(img)

        # å°è¯•åŠ è½½ä¸­æ–‡å­—ä½“
        font = None
        font_paths = [
            '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',
            '/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc',
            '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',
            '/System/Library/Fonts/PingFang.ttc',
        ]
        for fp in font_paths:
            if os.path.exists(fp):
                try:
                    font = ImageFont.truetype(fp, 48)
                    break
                except Exception:
                    continue

        if font is None:
            font = ImageFont.load_default()

        # ç»˜åˆ¶æ ‡é¢˜æ–‡å­—
        if title:
            text = title[:15]
            bbox = draw.textbbox((0, 0), text, font=font)
            tw = bbox[2] - bbox[0]
            x = (1080 - tw) // 2
            draw.text((x, 600), text, fill=(50, 50, 50), font=font)

        img.save(str(path))
        log.info(f'é»˜è®¤å°é¢å·²ç”Ÿæˆ: {path}')

    except ImportError:
        # æ²¡æœ‰ Pillowï¼Œåˆ›å»ºä¸€ä¸ªæœ€å°çš„ PNG
        import struct
        import zlib

        def create_minimal_png(width=1080, height=1440):
            raw = b''
            for _ in range(height):
                raw += b'\x00' + b'\xff\xf0\xf5' * width
            compressed = zlib.compress(raw)

            def chunk(ctype, data):
                c = ctype + data
                return struct.pack('>I', len(data)) + c + struct.pack('>I', zlib.crc32(c) & 0xffffffff)

            ihdr = struct.pack('>IIBBBBB', width, height, 8, 2, 0, 0, 0)
            return b'\x89PNG\r\n\x1a\n' + chunk(b'IHDR', ihdr) + chunk(b'IDAT', compressed) + chunk(b'IEND', b'')

        with open(str(path), 'wb') as f:
            f.write(create_minimal_png())
        log.info(f'é»˜è®¤å°é¢å·²ç”Ÿæˆï¼ˆæœ€å°PNGï¼‰: {path}')


def _save_report(title, content, tags, success, error=None):
    """ä¿å­˜å‘å¸ƒæŠ¥å‘Š"""
    report = {
        'time': datetime.now().isoformat(),
        'title': title,
        'content_length': len(content),
        'tags': tags or [],
        'result': {
            'success': success,
            'error': error
        }
    }
    report_file = LOG_DIR / f'report_{datetime.now():%Y%m%d_%H%M%S}.json'
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    log.info(f'å‘å¸ƒæŠ¥å‘Š: {report_file}')


# â”€â”€â”€ CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cmd_login(args):
    """ç™»å½•å‘½ä»¤"""
    from playwright.sync_api import sync_playwright

    with sync_playwright() as pw:
        ctx = create_browser_context(pw, headless=False)
        page = ctx.pages[0] if ctx.pages else ctx.new_page()

        if check_login(page):
            log.info('å·²ç»ç™»å½•ï¼Œæ— éœ€é‡å¤ç™»å½•')
            screenshot = SCREENSHOTS_DIR / f'already_logged_{datetime.now():%Y%m%d_%H%M%S}.png'
            page.screenshot(path=str(screenshot))
            print(json.dumps({
                'success': True,
                'status': 'already_logged_in',
                'screenshot': str(screenshot)
            }, ensure_ascii=False))
        else:
            qr_path = do_login(page, timeout=args.timeout)
            print(json.dumps({
                'success': True,
                'status': 'logged_in',
                'qr_screenshot': qr_path
            }, ensure_ascii=False))

        ctx.close()


def cmd_publish(args):
    """å‘å¸ƒå‘½ä»¤"""
    from playwright.sync_api import sync_playwright

    # è§£æå†…å®¹
    title = args.title
    content = args.content
    tags = args.tags.split(',') if args.tags else None
    images = args.images.split(',') if args.images else None

    # ä» JSON æ–‡ä»¶è¯»å–
    if args.file:
        with open(args.file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        title = title or data.get('title', '')
        content = content or data.get('content', '')
        tags = tags or data.get('tags', [])
        images = images or data.get('images', [])

    if not title or not content:
        print(json.dumps({
            'success': False,
            'error': 'å¿…é¡»æä¾›æ ‡é¢˜å’Œæ­£æ–‡'
        }, ensure_ascii=False))
        sys.exit(1)

    with sync_playwright() as pw:
        ctx = create_browser_context(pw, headless=args.headless)
        page = ctx.pages[0] if ctx.pages else ctx.new_page()

        # æ£€æŸ¥ç™»å½•
        if not check_login(page):
            print(json.dumps({
                'success': False,
                'error': 'æœªç™»å½•ï¼Œè¯·å…ˆæ‰§è¡Œ login å‘½ä»¤'
            }, ensure_ascii=False))
            ctx.close()
            sys.exit(1)

        # å‘å¸ƒ
        result = publish_note(
            page,
            title=title,
            content=content,
            tags=tags,
            images=images,
            dry_run=args.dry_run,
            auto_image=not args.no_auto_image,
            image_count=args.image_count
        )

        print(json.dumps(result, ensure_ascii=False, indent=2))
        ctx.close()
        sys.exit(0 if result['success'] else 1)


def cmd_status(args):
    """æ£€æŸ¥ç™»å½•çŠ¶æ€"""
    from playwright.sync_api import sync_playwright

    with sync_playwright() as pw:
        ctx = create_browser_context(pw, headless=True)
        page = ctx.pages[0] if ctx.pages else ctx.new_page()

        logged_in = check_login(page)
        result = {
            'logged_in': logged_in,
            'browser_data_exists': BROWSER_DATA.exists() and any(BROWSER_DATA.iterdir()),
            'checked_at': datetime.now().isoformat()
        }

        print(json.dumps(result, ensure_ascii=False, indent=2))
        ctx.close()


def cmd_generate(args):
    """AI ç”Ÿæˆå†…å®¹"""
    sys.path.insert(0, str(Path(__file__).parent))
    from content_gen import generate_content, save_content, list_templates

    if args.list_styles:
        templates = list_templates()
        print(json.dumps(templates, ensure_ascii=False, indent=2))
        return

    if not args.topic:
        print(json.dumps({'success': False, 'error': 'å¿…é¡»æä¾›ä¸»é¢˜ (--topic)'}, ensure_ascii=False))
        sys.exit(1)

    try:
        result = generate_content(
            topic=args.topic,
            style=args.style,
            extra_instructions=args.extra or '',
        )
        path = save_content(result)
        result['saved_to'] = path
        log.info(f'å†…å®¹å·²ç”Ÿæˆå¹¶ä¿å­˜: {path}')
        print(json.dumps(result, ensure_ascii=False, indent=2))
    except Exception as e:
        log.error(f'å†…å®¹ç”Ÿæˆå¤±è´¥: {e}')
        print(json.dumps({'success': False, 'error': str(e)}, ensure_ascii=False))
        sys.exit(1)


def cmd_schedule(args):
    """å®šæ—¶å‘å¸ƒç®¡ç†"""
    sys.path.insert(0, str(Path(__file__).parent))
    from schedule import (add_task, remove_task, list_tasks, get_task,
                          toggle_task, format_task_summary, update_cron_job_id)

    action = args.schedule_action

    if action == 'list':
        tasks = list_tasks()
        if not tasks:
            print(json.dumps({'tasks': [], 'message': 'æš‚æ— å®šæ—¶ä»»åŠ¡'}, ensure_ascii=False))
            return
        result = []
        for tid, task in tasks.items():
            result.append({**task, 'summary': format_task_summary(task)})
        print(json.dumps({'tasks': result, 'count': len(result)}, ensure_ascii=False, indent=2))

    elif action == 'add':
        if not args.topic:
            print(json.dumps({'success': False, 'error': 'å¿…é¡»æä¾› --topic'}, ensure_ascii=False))
            sys.exit(1)
        if not args.cron_expr and not args.at_time and not args.every_minutes:
            print(json.dumps({'success': False, 'error': 'å¿…é¡»æŒ‡å®šè°ƒåº¦æ–¹å¼: --cron / --at / --every'}, ensure_ascii=False))
            sys.exit(1)

        result = add_task(
            topic=args.topic,
            style=args.style,
            extra=args.extra or '',
            cron_expr=args.cron_expr,
            at_time=args.at_time,
            every_minutes=int(args.every_minutes) if args.every_minutes else None,
            tz=args.tz,
            headless=True,
            name=args.name,
        )

        # è¾“å‡º cron_job ä¾› agent è°ƒç”¨ OpenClaw cron API åˆ›å»º
        print(json.dumps({
            'success': True,
            'task_id': result['task_id'],
            'cron_job': result['cron_job'],
            'message': 'æœ¬åœ°ä»»åŠ¡å·²åˆ›å»ºï¼Œè¯·ç”¨ cron tool çš„ add action å°† cron_job æäº¤ç»™ OpenClaw',
            'summary': format_task_summary(result['local_record']),
        }, ensure_ascii=False, indent=2))

    elif action == 'remove':
        if not args.task_id:
            print(json.dumps({'success': False, 'error': 'å¿…é¡»æä¾› --task-id'}, ensure_ascii=False))
            sys.exit(1)
        cron_job_id = remove_task(args.task_id)
        print(json.dumps({
            'success': True,
            'task_id': args.task_id,
            'cron_job_id': cron_job_id,
            'message': f'æœ¬åœ°ä»»åŠ¡å·²åˆ é™¤ã€‚' + (f'è¯·ç”¨ cron tool remove åˆ é™¤ OpenClaw cron job: {cron_job_id}' if cron_job_id else 'æ— å…³è”çš„ cron job'),
        }, ensure_ascii=False, indent=2))

    elif action == 'enable':
        if not args.task_id:
            print(json.dumps({'success': False, 'error': 'å¿…é¡»æä¾› --task-id'}, ensure_ascii=False))
            sys.exit(1)
        task = toggle_task(args.task_id, True)
        if task:
            print(json.dumps({
                'success': True, 'task_id': args.task_id, 'enabled': True,
                'cron_job_id': task.get('cron_job_id'),
                'message': 'å·²å¯ç”¨ã€‚' + (f'è¯·ç”¨ cron tool update å¯ç”¨ OpenClaw cron job: {task.get("cron_job_id")}' if task.get('cron_job_id') else ''),
            }, ensure_ascii=False, indent=2))
        else:
            print(json.dumps({'success': False, 'error': f'ä»»åŠ¡ä¸å­˜åœ¨: {args.task_id}'}, ensure_ascii=False))

    elif action == 'disable':
        if not args.task_id:
            print(json.dumps({'success': False, 'error': 'å¿…é¡»æä¾› --task-id'}, ensure_ascii=False))
            sys.exit(1)
        task = toggle_task(args.task_id, False)
        if task:
            print(json.dumps({
                'success': True, 'task_id': args.task_id, 'enabled': False,
                'cron_job_id': task.get('cron_job_id'),
                'message': 'å·²æš‚åœã€‚' + (f'è¯·ç”¨ cron tool update æš‚åœ OpenClaw cron job: {task.get("cron_job_id")}' if task.get('cron_job_id') else ''),
            }, ensure_ascii=False, indent=2))
        else:
            print(json.dumps({'success': False, 'error': f'ä»»åŠ¡ä¸å­˜åœ¨: {args.task_id}'}, ensure_ascii=False))

    elif action == 'link':
        # å›å¡« cron_job_id
        if not args.task_id or not args.cron_job_id:
            print(json.dumps({'success': False, 'error': 'å¿…é¡»æä¾› --task-id å’Œ --cron-job-id'}, ensure_ascii=False))
            sys.exit(1)
        ok = update_cron_job_id(args.task_id, args.cron_job_id)
        print(json.dumps({'success': ok, 'task_id': args.task_id, 'cron_job_id': args.cron_job_id}, ensure_ascii=False))

    else:
        print(json.dumps({'success': False, 'error': f'æœªçŸ¥æ“ä½œ: {action}'}, ensure_ascii=False))
        sys.exit(1)


def cmd_trending(args):
    """çƒ­ç‚¹æ•°æ®é‡‡é›†"""
    sys.path.insert(0, str(Path(__file__).parent))
    from trending import fetch_trending, fetch_all_trending, get_top_topics, format_trending_text, SOURCES

    action = args.trending_action

    if action == 'sources':
        for key, info in SOURCES.items():
            print(f"  {info['emoji']} {key} â€” {info['name']}")
        return

    if action == 'topics':
        topics = get_top_topics(limit=args.limit)
        print(json.dumps(topics, ensure_ascii=False, indent=2))
        return

    # fetch
    if args.no_cache:
        data = fetch_trending(sources=args.sources, limit=args.limit)
    else:
        data = fetch_all_trending(limit=args.limit)
        if args.sources:
            data = {k: v for k, v in data.items() if k in args.sources or k.startswith('_')}

    if args.text:
        print(format_trending_text(data, limit=args.limit))
    else:
        print(json.dumps(data, ensure_ascii=False, indent=2))


def cmd_hot(args):
    """æ ¹æ®çƒ­ç‚¹è¯é¢˜ä¸€é”®ç”Ÿæˆå†…å®¹ï¼ˆå¯é€‰å‘å¸ƒï¼‰"""
    sys.path.insert(0, str(Path(__file__).parent))
    from trending import get_top_topics
    from content_gen import generate_content, save_content

    # è·å–çƒ­ç‚¹è¯é¢˜
    topics = get_top_topics(limit=30)
    if not topics:
        print(json.dumps({'success': False, 'error': 'è·å–çƒ­ç‚¹å¤±è´¥'}, ensure_ascii=False))
        sys.exit(1)

    # é€‰æ‹©è¯é¢˜
    if args.pick:
        # æŒ‰åºå·é€‰
        idx = args.pick - 1
        if idx < 0 or idx >= len(topics):
            print(json.dumps({'success': False, 'error': f'åºå·è¶…å‡ºèŒƒå›´ (1-{len(topics)})'}, ensure_ascii=False))
            sys.exit(1)
        chosen = topics[idx]
    elif args.keyword:
        # æŒ‰å…³é”®è¯åŒ¹é…
        matched = [t for t in topics if args.keyword in t['title']]
        if not matched:
            print(json.dumps({
                'success': False,
                'error': f'æœªåŒ¹é…åˆ°å«ã€Œ{args.keyword}ã€çš„çƒ­ç‚¹',
                'available': [t['title'] for t in topics[:10]],
            }, ensure_ascii=False, indent=2))
            sys.exit(1)
        chosen = matched[0]
    else:
        # é»˜è®¤å–ç¬¬ä¸€ä¸ªéç½®é¡¶çƒ­ç‚¹
        chosen = topics[0]

    topic = chosen['title']
    log.info(f'é€‰ä¸­çƒ­ç‚¹: {topic} (æ¥æº: {chosen["source"]})')

    # ç”Ÿæˆå†…å®¹
    extra = args.extra or ''
    extra_full = f'åŸºäºå½“å‰çƒ­ç‚¹è¯é¢˜åˆ›ä½œï¼Œæ¥æº: {chosen["source"]}ã€‚{extra}'.strip()
    try:
        result = generate_content(
            topic=topic,
            style=args.style,
            extra_instructions=extra_full,
        )
        path = save_content(result)
        result['saved_to'] = path
        result['hot_topic'] = chosen
        log.info(f'çƒ­ç‚¹å†…å®¹å·²ç”Ÿæˆ: {result["title"]}')
    except Exception as e:
        print(json.dumps({'success': False, 'error': str(e)}, ensure_ascii=False))
        sys.exit(1)

    if args.publish:
        # ä¸€é”®å‘å¸ƒ
        from playwright.sync_api import sync_playwright
        title = result['title']
        content = result['content']
        tags = result.get('tags', [])

        with sync_playwright() as pw:
            ctx = create_browser_context(pw, headless=args.headless)
            page = ctx.pages[0] if ctx.pages else ctx.new_page()

            if not check_login(page):
                print(json.dumps({'success': False, 'error': 'æœªç™»å½•ï¼Œè¯·å…ˆæ‰§è¡Œ login å‘½ä»¤'}, ensure_ascii=False))
                ctx.close()
                sys.exit(1)

            pub_result = publish_note(
                page, title=title, content=content, tags=tags,
                dry_run=args.dry_run, auto_image=True,
                image_count=args.image_count,
            )
            pub_result['generated_content'] = path
            pub_result['hot_topic'] = chosen
            print(json.dumps(pub_result, ensure_ascii=False, indent=2))
            ctx.close()
            sys.exit(0 if pub_result['success'] else 1)
    else:
        print(json.dumps(result, ensure_ascii=False, indent=2))


def cmd_keystore(args):
    """API Key åŠ å¯†ç®¡ç†"""
    sys.path.insert(0, str(Path(__file__).parent))
    from keystore import encrypt_keys, decrypt_keys, get_api_key, migrate_to_encrypted, KEYS_FILE, SALT_FILE
    import os

    password = os.environ.get('XHS_KEY_PASSWORD', '')
    action = args.key_action

    if action == 'status':
        try:
            from cryptography.fernet import Fernet
            has_crypto = True
        except ImportError:
            has_crypto = False
        print(json.dumps({
            'encrypted_file_exists': KEYS_FILE.exists(),
            'encrypted_file': str(KEYS_FILE),
            'has_cryptography': has_crypto,
            'salt_exists': SALT_FILE.exists(),
        }, ensure_ascii=False, indent=2))

    elif action == 'migrate':
        result = migrate_to_encrypted(password)
        print(json.dumps(result, ensure_ascii=False, indent=2))

    elif action == 'list':
        if not KEYS_FILE.exists():
            print(json.dumps({'keys': [], 'message': 'å°šæœªåˆ›å»ºåŠ å¯†å­˜å‚¨'}, ensure_ascii=False))
            return
        try:
            keys = decrypt_keys(password)
            masked = {k: v[:4] + '***' + v[-4:] if len(v) > 8 else '***' for k, v in keys.items()}
            print(json.dumps({'keys': masked}, ensure_ascii=False, indent=2))
        except Exception as e:
            print(json.dumps({'error': str(e)}, ensure_ascii=False))

    elif action == 'set':
        if not args.key_name or not args.key_value:
            print(json.dumps({'success': False, 'error': 'å¿…é¡»æä¾› --key-name å’Œ --key-value'}, ensure_ascii=False))
            sys.exit(1)
        existing = {}
        if KEYS_FILE.exists():
            try:
                existing = decrypt_keys(password)
            except Exception:
                pass
        existing[args.key_name] = args.key_value
        path = encrypt_keys(existing, password)
        print(json.dumps({'success': True, 'key': args.key_name, 'file': path}, ensure_ascii=False))

    elif action == 'get':
        if not args.key_name:
            print(json.dumps({'success': False, 'error': 'å¿…é¡»æä¾› --key-name'}, ensure_ascii=False))
            sys.exit(1)
        val = get_api_key(args.key_name, password)
        if val:
            print(json.dumps({'key': args.key_name, 'found': True, 'preview': val[:4] + '***'}, ensure_ascii=False))
        else:
            print(json.dumps({'key': args.key_name, 'found': False}, ensure_ascii=False))


def cmd_generate_and_publish(args):
    """AI ç”Ÿæˆå†…å®¹ + è‡ªåŠ¨å‘å¸ƒï¼ˆä¸€é”®æµç¨‹ï¼‰"""
    from playwright.sync_api import sync_playwright
    sys.path.insert(0, str(Path(__file__).parent))
    from content_gen import generate_content, save_content

    # 1. ç”Ÿæˆå†…å®¹
    log.info(f'ä¸€é”®ç”Ÿæˆå‘å¸ƒ: ä¸»é¢˜={args.topic}, é£æ ¼={args.style}')
    try:
        content_data = generate_content(
            topic=args.topic,
            style=args.style,
            extra_instructions=args.extra or '',
        )
        path = save_content(content_data)
        log.info(f'å†…å®¹å·²ç”Ÿæˆ: {content_data["title"]}')
    except Exception as e:
        print(json.dumps({'success': False, 'phase': 'generate', 'error': str(e)}, ensure_ascii=False))
        sys.exit(1)

    title = content_data['title']
    content = content_data['content']
    tags = content_data.get('tags', [])

    if args.dry_run:
        print(json.dumps({
            'success': True,
            'dry_run': True,
            'title': title,
            'content': content,
            'tags': tags,
            'saved_to': path,
        }, ensure_ascii=False, indent=2))
        return

    # 2. å‘å¸ƒ
    with sync_playwright() as pw:
        ctx = create_browser_context(pw, headless=args.headless)
        page = ctx.pages[0] if ctx.pages else ctx.new_page()

        if not check_login(page):
            print(json.dumps({'success': False, 'error': 'æœªç™»å½•ï¼Œè¯·å…ˆæ‰§è¡Œ login å‘½ä»¤'}, ensure_ascii=False))
            ctx.close()
            sys.exit(1)

        result = publish_note(
            page,
            title=title,
            content=content,
            tags=tags,
            dry_run=False,
            auto_image=not args.no_auto_image,
            image_count=args.image_count,
        )
        result['generated_content'] = path
        print(json.dumps(result, ensure_ascii=False, indent=2))
        ctx.close()
        sys.exit(0 if result['success'] else 1)


def main():
    parser = argparse.ArgumentParser(description='å°çº¢ä¹¦è‡ªåŠ¨åŒ–å‘å¸ƒå·¥å…·')
    sub = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')

    # login
    p_login = sub.add_parser('login', help='æ‰«ç ç™»å½•å°çº¢ä¹¦')
    p_login.add_argument('--timeout', type=int, default=300, help='ç™»å½•è¶…æ—¶ç§’æ•°ï¼ˆé»˜è®¤300ï¼‰')

    # publish
    p_pub = sub.add_parser('publish', help='å‘å¸ƒç¬”è®°')
    p_pub.add_argument('--title', help='ç¬”è®°æ ‡é¢˜')
    p_pub.add_argument('--content', help='ç¬”è®°æ­£æ–‡')
    p_pub.add_argument('--tags', help='æ ‡ç­¾ï¼Œé€—å·åˆ†éš”')
    p_pub.add_argument('--images', help='å›¾ç‰‡è·¯å¾„ï¼Œé€—å·åˆ†éš”')
    p_pub.add_argument('--file', help='ä» JSON æ–‡ä»¶è¯»å–å†…å®¹')
    p_pub.add_argument('--dry-run', action='store_true', help='è¯•è¿è¡Œï¼Œä¸å®é™…å‘å¸ƒ')
    p_pub.add_argument('--headless', action='store_true', help='æ— å¤´æ¨¡å¼è¿è¡Œ')
    p_pub.add_argument('--no-auto-image', action='store_true', help='ç¦ç”¨è‡ªåŠ¨ AI é…å›¾')
    p_pub.add_argument('--image-count', type=int, default=1, help='è‡ªåŠ¨ç”Ÿæˆå›¾ç‰‡æ•°é‡ï¼ˆ1-9ï¼Œé»˜è®¤1ï¼‰')

    # status
    p_status = sub.add_parser('status', help='æ£€æŸ¥ç™»å½•çŠ¶æ€')

    # generate - AI ç”Ÿæˆå†…å®¹
    p_gen = sub.add_parser('generate', help='AI ç”Ÿæˆå°çº¢ä¹¦å†…å®¹')
    p_gen.add_argument('--topic', '-t', help='ä¸»é¢˜/å…³é”®è¯')
    p_gen.add_argument('--style', '-s', default='default',
                       help='æ–‡æ¡ˆé£æ ¼: default/review/tutorial/daily')
    p_gen.add_argument('--extra', '-e', help='é¢å¤–æŒ‡ä»¤')
    p_gen.add_argument('--list-styles', action='store_true', help='åˆ—å‡ºå¯ç”¨é£æ ¼')

    # auto - ä¸€é”®ç”Ÿæˆ+å‘å¸ƒ
    p_auto = sub.add_parser('auto', help='AI ç”Ÿæˆå†…å®¹å¹¶è‡ªåŠ¨å‘å¸ƒ')
    p_auto.add_argument('--topic', '-t', required=True, help='ä¸»é¢˜/å…³é”®è¯')
    p_auto.add_argument('--style', '-s', default='default',
                        help='æ–‡æ¡ˆé£æ ¼: default/review/tutorial/daily')
    p_auto.add_argument('--extra', '-e', help='é¢å¤–æŒ‡ä»¤')
    p_auto.add_argument('--dry-run', action='store_true', help='åªç”Ÿæˆä¸å‘å¸ƒ')
    p_auto.add_argument('--headless', action='store_true', help='æ— å¤´æ¨¡å¼')
    p_auto.add_argument('--no-auto-image', action='store_true', help='ç¦ç”¨è‡ªåŠ¨é…å›¾')
    p_auto.add_argument('--image-count', type=int, default=3, help='è‡ªåŠ¨ç”Ÿæˆå›¾ç‰‡æ•°é‡ï¼ˆ1-9ï¼Œé»˜è®¤3ï¼‰')

    # schedule - å®šæ—¶å‘å¸ƒç®¡ç†
    p_sched = sub.add_parser('schedule', help='å®šæ—¶å‘å¸ƒç®¡ç†')
    p_sched.add_argument('schedule_action',
                         choices=['list', 'add', 'remove', 'enable', 'disable', 'link'],
                         help='æ“ä½œ: list/add/remove/enable/disable/link')
    p_sched.add_argument('--topic', '-t', help='å‘å¸ƒä¸»é¢˜')
    p_sched.add_argument('--style', '-s', default='default', help='æ–‡æ¡ˆé£æ ¼')
    p_sched.add_argument('--extra', '-e', help='é¢å¤–æŒ‡ä»¤')
    p_sched.add_argument('--cron', dest='cron_expr', help='cron è¡¨è¾¾å¼ (å¦‚ "0 8 * * *")')
    p_sched.add_argument('--at', dest='at_time', help='ä¸€æ¬¡æ€§å‘å¸ƒæ—¶é—´ ISO æ ¼å¼ (å¦‚ "2026-02-13T10:00:00")')
    p_sched.add_argument('--every', dest='every_minutes', help='æ¯éš” N åˆ†é’Ÿå‘å¸ƒ')
    p_sched.add_argument('--tz', default='Asia/Shanghai', help='æ—¶åŒº (é»˜è®¤ Asia/Shanghai)')
    p_sched.add_argument('--name', help='ä»»åŠ¡åç§°')
    p_sched.add_argument('--task-id', dest='task_id', help='ä»»åŠ¡ ID')
    p_sched.add_argument('--cron-job-id', dest='cron_job_id', help='OpenClaw cron job ID (link æ“ä½œç”¨)')

    # trending - çƒ­ç‚¹æ•°æ®é‡‡é›†
    p_trend = sub.add_parser('trending', help='çƒ­ç‚¹æ•°æ®é‡‡é›†')
    p_trend.add_argument('trending_action', choices=['fetch', 'topics', 'sources'],
                         help='æ“ä½œ: fetch=é‡‡é›†çƒ­æ¦œ, topics=æå–è¯é¢˜, sources=åˆ—å‡ºæ•°æ®æº')
    p_trend.add_argument('--source', '-s', action='append', dest='sources',
                         help='æ•°æ®æº (å¯å¤šæ¬¡æŒ‡å®š): baidu/toutiao/bilibili')
    p_trend.add_argument('--limit', '-n', type=int, default=20, help='æ¯æºè¿”å›æ¡æ•° (é»˜è®¤20)')
    p_trend.add_argument('--no-cache', action='store_true', help='è·³è¿‡ç¼“å­˜')
    p_trend.add_argument('--text', action='store_true', help='è¾“å‡ºå¯è¯»æ–‡æœ¬ï¼ˆé»˜è®¤ JSONï¼‰')

    # hot - æ ¹æ®çƒ­ç‚¹ä¸€é”®ç”Ÿæˆå†…å®¹
    p_hot = sub.add_parser('hot', help='æ ¹æ®çƒ­ç‚¹è¯é¢˜ç”Ÿæˆå†…å®¹')
    p_hot.add_argument('--pick', '-p', type=int, help='é€‰æ‹©ç¬¬ N ä¸ªçƒ­ç‚¹ï¼ˆä»1å¼€å§‹ï¼‰')
    p_hot.add_argument('--keyword', '-k', help='æŒ‰å…³é”®è¯åŒ¹é…çƒ­ç‚¹')
    p_hot.add_argument('--style', '-s', default='default', help='æ–‡æ¡ˆé£æ ¼')
    p_hot.add_argument('--extra', '-e', help='é¢å¤–æŒ‡ä»¤')
    p_hot.add_argument('--publish', action='store_true', help='ç”Ÿæˆåç›´æ¥å‘å¸ƒ')
    p_hot.add_argument('--dry-run', action='store_true', help='è¯•è¿è¡Œ')
    p_hot.add_argument('--headless', action='store_true', help='æ— å¤´æ¨¡å¼')
    p_hot.add_argument('--image-count', type=int, default=3, help='è‡ªåŠ¨ç”Ÿæˆå›¾ç‰‡æ•°é‡ï¼ˆ1-9ï¼Œé»˜è®¤3ï¼‰')

    # keystore - API Key åŠ å¯†ç®¡ç†
    p_key = sub.add_parser('keystore', help='API Key åŠ å¯†ç®¡ç†')
    p_key.add_argument('key_action', choices=['status', 'migrate', 'list', 'set', 'get'],
                       help='æ“ä½œ: status/migrate/list/set/get')
    p_key.add_argument('--key-name', help='Key åç§°')
    p_key.add_argument('--key-value', help='Key å€¼ï¼ˆset æ“ä½œç”¨ï¼‰')

    args = parser.parse_args()

    if args.command == 'login':
        cmd_login(args)
    elif args.command == 'publish':
        cmd_publish(args)
    elif args.command == 'status':
        cmd_status(args)
    elif args.command == 'generate':
        cmd_generate(args)
    elif args.command == 'auto':
        cmd_generate_and_publish(args)
    elif args.command == 'schedule':
        cmd_schedule(args)
    elif args.command == 'trending':
        cmd_trending(args)
    elif args.command == 'hot':
        cmd_hot(args)
    elif args.command == 'keystore':
        cmd_keystore(args)
    else:
        parser.print_help()
        sys.exit(1)


if __name__ == '__main__':
    main()
